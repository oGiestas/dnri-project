Using factor graph MLP encoder.
ENCODER:  RefMLPEncoder(
  (mlp1): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=160, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp2): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=512, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp3): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp4): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=768, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_out): Sequential(
    (0): Linear(in_features=256, out_features=256, bias=True)
    (1): ELU(alpha=1.0, inplace=True)
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ELU(alpha=1.0, inplace=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
)
Using learned recurrent interaction net decoder.
DECODER:  GraphRNNDecoder(
  (msg_fc1): ModuleList(
    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)
  )
  (msg_fc2): ModuleList(
    (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
  )
  (hidden_r): Linear(in_features=256, out_features=256, bias=False)
  (hidden_i): Linear(in_features=256, out_features=256, bias=False)
  (hidden_h): Linear(in_features=256, out_features=256, bias=False)
  (input_r): Linear(in_features=4, out_features=256, bias=True)
  (input_i): Linear(in_features=4, out_features=256, bias=True)
  (input_n): Linear(in_features=4, out_features=256, bias=True)
  (out_fc1): Linear(in_features=256, out_features=256, bias=True)
  (out_fc2): Linear(in_features=256, out_features=256, bias=True)
  (out_fc3): Linear(in_features=256, out_features=4, bias=True)
)
USING UNIFORM PRIOR
EPOCH 1 0
/mnt/aiongpfs/users/rgiesta/bsps6/dnri/dnri/models/decoders.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  hidden = torch.cuda.FloatTensor(inputs.size(0), inputs.size(2), self.msg_out_shape).fill_(0.)
BEST VAL RESULT. SAVING MODEL...
EPOCH 1 EVAL: 
	CURRENT VAL LOSS: 30.196367
	BEST VAL LOSS:    30.196367
	BEST VAL EPOCH:   1
EPOCH 2 9.07905387878418
BEST VAL RESULT. SAVING MODEL...
EPOCH 2 EVAL: 
	CURRENT VAL LOSS: -0.099589
	BEST VAL LOSS:    -0.099589
	BEST VAL EPOCH:   2
EPOCH 3 8.145477771759033
BEST VAL RESULT. SAVING MODEL...
EPOCH 3 EVAL: 
	CURRENT VAL LOSS: -0.221016
	BEST VAL LOSS:    -0.221016
	BEST VAL EPOCH:   3
EPOCH 4 8.14562726020813
BEST VAL RESULT. SAVING MODEL...
EPOCH 4 EVAL: 
	CURRENT VAL LOSS: -0.817797
	BEST VAL LOSS:    -0.817797
	BEST VAL EPOCH:   4
EPOCH 5 8.148045778274536
BEST VAL RESULT. SAVING MODEL...
EPOCH 5 EVAL: 
	CURRENT VAL LOSS: -1.224063
	BEST VAL LOSS:    -1.224063
	BEST VAL EPOCH:   5
EPOCH 6 8.146984815597534
BEST VAL RESULT. SAVING MODEL...
EPOCH 6 EVAL: 
	CURRENT VAL LOSS: -1.315341
	BEST VAL LOSS:    -1.315341
	BEST VAL EPOCH:   6
EPOCH 7 8.146023273468018
BEST VAL RESULT. SAVING MODEL...
EPOCH 7 EVAL: 
	CURRENT VAL LOSS: -1.707856
	BEST VAL LOSS:    -1.707856
	BEST VAL EPOCH:   7
EPOCH 8 8.152470827102661
BEST VAL RESULT. SAVING MODEL...
EPOCH 8 EVAL: 
	CURRENT VAL LOSS: -1.737992
	BEST VAL LOSS:    -1.737992
	BEST VAL EPOCH:   8
EPOCH 9 8.133659362792969
BEST VAL RESULT. SAVING MODEL...
EPOCH 9 EVAL: 
	CURRENT VAL LOSS: -1.833685
	BEST VAL LOSS:    -1.833685
	BEST VAL EPOCH:   9
EPOCH 10 8.146598815917969
BEST VAL RESULT. SAVING MODEL...
EPOCH 10 EVAL: 
	CURRENT VAL LOSS: -1.983813
	BEST VAL LOSS:    -1.983813
	BEST VAL EPOCH:   10
EPOCH 11 8.142041444778442
BEST VAL RESULT. SAVING MODEL...
EPOCH 11 EVAL: 
	CURRENT VAL LOSS: -2.148143
	BEST VAL LOSS:    -2.148143
	BEST VAL EPOCH:   11
EPOCH 12 8.141640186309814
BEST VAL RESULT. SAVING MODEL...
EPOCH 12 EVAL: 
	CURRENT VAL LOSS: -2.414428
	BEST VAL LOSS:    -2.414428
	BEST VAL EPOCH:   12
EPOCH 13 8.146036863327026
EPOCH 13 EVAL: 
	CURRENT VAL LOSS: -2.361699
	BEST VAL LOSS:    -2.414428
	BEST VAL EPOCH:   12
EPOCH 14 8.12938117980957
BEST VAL RESULT. SAVING MODEL...
EPOCH 14 EVAL: 
	CURRENT VAL LOSS: -2.589293
	BEST VAL LOSS:    -2.589293
	BEST VAL EPOCH:   14
EPOCH 15 8.146909236907959
EPOCH 15 EVAL: 
	CURRENT VAL LOSS: -2.483075
	BEST VAL LOSS:    -2.589293
	BEST VAL EPOCH:   14
EPOCH 16 8.127045392990112
BEST VAL RESULT. SAVING MODEL...
EPOCH 16 EVAL: 
	CURRENT VAL LOSS: -2.589864
	BEST VAL LOSS:    -2.589864
	BEST VAL EPOCH:   16
EPOCH 17 8.142972707748413
BEST VAL RESULT. SAVING MODEL...
EPOCH 17 EVAL: 
	CURRENT VAL LOSS: -2.599611
	BEST VAL LOSS:    -2.599611
	BEST VAL EPOCH:   17
EPOCH 18 8.14406156539917
BEST VAL RESULT. SAVING MODEL...
EPOCH 18 EVAL: 
	CURRENT VAL LOSS: -2.712238
	BEST VAL LOSS:    -2.712238
	BEST VAL EPOCH:   18
EPOCH 19 8.146050930023193
BEST VAL RESULT. SAVING MODEL...
EPOCH 19 EVAL: 
	CURRENT VAL LOSS: -2.809747
	BEST VAL LOSS:    -2.809747
	BEST VAL EPOCH:   19
EPOCH 20 8.152398109436035
BEST VAL RESULT. SAVING MODEL...
EPOCH 20 EVAL: 
	CURRENT VAL LOSS: -2.839276
	BEST VAL LOSS:    -2.839276
	BEST VAL EPOCH:   20
EPOCH 21 8.157267093658447
EPOCH 21 EVAL: 
	CURRENT VAL LOSS: -2.827432
	BEST VAL LOSS:    -2.839276
	BEST VAL EPOCH:   20
EPOCH 22 8.125800371170044
BEST VAL RESULT. SAVING MODEL...
EPOCH 22 EVAL: 
	CURRENT VAL LOSS: -2.879519
	BEST VAL LOSS:    -2.879519
	BEST VAL EPOCH:   22
EPOCH 23 8.127373456954956
EPOCH 23 EVAL: 
	CURRENT VAL LOSS: -2.875205
	BEST VAL LOSS:    -2.879519
	BEST VAL EPOCH:   22
EPOCH 24 8.118235111236572
BEST VAL RESULT. SAVING MODEL...
EPOCH 24 EVAL: 
	CURRENT VAL LOSS: -2.893339
	BEST VAL LOSS:    -2.893339
	BEST VAL EPOCH:   24
EPOCH 25 8.14702820777893
BEST VAL RESULT. SAVING MODEL...
EPOCH 25 EVAL: 
	CURRENT VAL LOSS: -2.995720
	BEST VAL LOSS:    -2.995720
	BEST VAL EPOCH:   25
EPOCH 26 8.137741088867188
EPOCH 26 EVAL: 
	CURRENT VAL LOSS: -2.989624
	BEST VAL LOSS:    -2.995720
	BEST VAL EPOCH:   25
EPOCH 27 8.13843560218811
EPOCH 27 EVAL: 
	CURRENT VAL LOSS: -2.941382
	BEST VAL LOSS:    -2.995720
	BEST VAL EPOCH:   25
EPOCH 28 8.132182121276855
EPOCH 28 EVAL: 
	CURRENT VAL LOSS: -2.872749
	BEST VAL LOSS:    -2.995720
	BEST VAL EPOCH:   25
EPOCH 29 8.1473970413208
BEST VAL RESULT. SAVING MODEL...
EPOCH 29 EVAL: 
	CURRENT VAL LOSS: -3.022726
	BEST VAL LOSS:    -3.022726
	BEST VAL EPOCH:   29
EPOCH 30 8.147560596466064
BEST VAL RESULT. SAVING MODEL...
EPOCH 30 EVAL: 
	CURRENT VAL LOSS: -3.083866
	BEST VAL LOSS:    -3.083866
	BEST VAL EPOCH:   30
EPOCH 31 8.140631437301636
BEST VAL RESULT. SAVING MODEL...
EPOCH 31 EVAL: 
	CURRENT VAL LOSS: -3.152179
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 32 8.12559175491333
EPOCH 32 EVAL: 
	CURRENT VAL LOSS: -3.051350
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 33 8.1339750289917
EPOCH 33 EVAL: 
	CURRENT VAL LOSS: -3.063564
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 34 8.129032135009766
EPOCH 34 EVAL: 
	CURRENT VAL LOSS: -3.145198
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 35 8.125471591949463
EPOCH 35 EVAL: 
	CURRENT VAL LOSS: -3.098758
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 36 8.119663715362549
EPOCH 36 EVAL: 
	CURRENT VAL LOSS: -3.069529
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 37 8.106622695922852
EPOCH 37 EVAL: 
	CURRENT VAL LOSS: -3.094447
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 38 8.109743356704712
EPOCH 38 EVAL: 
	CURRENT VAL LOSS: -3.053259
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 39 8.126652240753174
EPOCH 39 EVAL: 
	CURRENT VAL LOSS: -3.111431
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 40 8.114798307418823
EPOCH 40 EVAL: 
	CURRENT VAL LOSS: -3.071338
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 41 8.120636701583862
BEST VAL RESULT. SAVING MODEL...
EPOCH 41 EVAL: 
	CURRENT VAL LOSS: -3.206131
	BEST VAL LOSS:    -3.206131
	BEST VAL EPOCH:   41
EPOCH 42 8.150073051452637
EPOCH 42 EVAL: 
	CURRENT VAL LOSS: -3.150799
	BEST VAL LOSS:    -3.206131
	BEST VAL EPOCH:   41
EPOCH 43 8.133249759674072
EPOCH 43 EVAL: 
	CURRENT VAL LOSS: -3.020304
	BEST VAL LOSS:    -3.206131
	BEST VAL EPOCH:   41
EPOCH 44 8.124705791473389
EPOCH 44 EVAL: 
	CURRENT VAL LOSS: -3.127894
	BEST VAL LOSS:    -3.206131
	BEST VAL EPOCH:   41
EPOCH 45 8.11426591873169
EPOCH 45 EVAL: 
	CURRENT VAL LOSS: -3.151528
	BEST VAL LOSS:    -3.206131
	BEST VAL EPOCH:   41
EPOCH 46 8.13264775276184
EPOCH 46 EVAL: 
	CURRENT VAL LOSS: -3.175980
	BEST VAL LOSS:    -3.206131
	BEST VAL EPOCH:   41
EPOCH 47 8.143304347991943
EPOCH 47 EVAL: 
	CURRENT VAL LOSS: -3.186850
	BEST VAL LOSS:    -3.206131
	BEST VAL EPOCH:   41
EPOCH 48 8.13052749633789
EPOCH 48 EVAL: 
	CURRENT VAL LOSS: -3.204509
	BEST VAL LOSS:    -3.206131
	BEST VAL EPOCH:   41
EPOCH 49 8.115946769714355
BEST VAL RESULT. SAVING MODEL...
EPOCH 49 EVAL: 
	CURRENT VAL LOSS: -3.233328
	BEST VAL LOSS:    -3.233328
	BEST VAL EPOCH:   49
EPOCH 50 8.14270305633545
EPOCH 50 EVAL: 
	CURRENT VAL LOSS: -3.175600
	BEST VAL LOSS:    -3.233328
	BEST VAL EPOCH:   49
