Using factor graph MLP encoder.
ENCODER:  RefMLPEncoder(
  (mlp1): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=160, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp2): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=512, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp3): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp4): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=768, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_out): Sequential(
    (0): Linear(in_features=256, out_features=256, bias=True)
    (1): ELU(alpha=1.0, inplace=True)
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ELU(alpha=1.0, inplace=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
)
Using learned recurrent interaction net decoder.
DECODER:  GraphRNNDecoder(
  (msg_fc1): ModuleList(
    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)
  )
  (msg_fc2): ModuleList(
    (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
  )
  (hidden_r): Linear(in_features=256, out_features=256, bias=False)
  (hidden_i): Linear(in_features=256, out_features=256, bias=False)
  (hidden_h): Linear(in_features=256, out_features=256, bias=False)
  (input_r): Linear(in_features=4, out_features=256, bias=True)
  (input_i): Linear(in_features=4, out_features=256, bias=True)
  (input_n): Linear(in_features=4, out_features=256, bias=True)
  (out_fc1): Linear(in_features=256, out_features=256, bias=True)
  (out_fc2): Linear(in_features=256, out_features=256, bias=True)
  (out_fc3): Linear(in_features=256, out_features=4, bias=True)
)
USING UNIFORM PRIOR
EPOCH 1 0
/mnt/aiongpfs/users/rgiesta/bsps6/dnri/dnri/models/decoders.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  hidden = torch.cuda.FloatTensor(inputs.size(0), inputs.size(2), self.msg_out_shape).fill_(0.)
BEST VAL RESULT. SAVING MODEL...
EPOCH 1 EVAL: 
	CURRENT VAL LOSS: 5.571706
	BEST VAL LOSS:    5.571706
	BEST VAL EPOCH:   1
EPOCH 2 9.056652545928955
BEST VAL RESULT. SAVING MODEL...
EPOCH 2 EVAL: 
	CURRENT VAL LOSS: -0.769393
	BEST VAL LOSS:    -0.769393
	BEST VAL EPOCH:   2
EPOCH 3 8.126107215881348
BEST VAL RESULT. SAVING MODEL...
EPOCH 3 EVAL: 
	CURRENT VAL LOSS: -0.970616
	BEST VAL LOSS:    -0.970616
	BEST VAL EPOCH:   3
EPOCH 4 8.12543272972107
BEST VAL RESULT. SAVING MODEL...
EPOCH 4 EVAL: 
	CURRENT VAL LOSS: -1.127949
	BEST VAL LOSS:    -1.127949
	BEST VAL EPOCH:   4
EPOCH 5 8.125513076782227
BEST VAL RESULT. SAVING MODEL...
EPOCH 5 EVAL: 
	CURRENT VAL LOSS: -1.513557
	BEST VAL LOSS:    -1.513557
	BEST VAL EPOCH:   5
EPOCH 6 8.126343011856079
BEST VAL RESULT. SAVING MODEL...
EPOCH 6 EVAL: 
	CURRENT VAL LOSS: -1.901017
	BEST VAL LOSS:    -1.901017
	BEST VAL EPOCH:   6
EPOCH 7 8.134127140045166
EPOCH 7 EVAL: 
	CURRENT VAL LOSS: -1.616182
	BEST VAL LOSS:    -1.901017
	BEST VAL EPOCH:   6
EPOCH 8 8.12077283859253
BEST VAL RESULT. SAVING MODEL...
EPOCH 8 EVAL: 
	CURRENT VAL LOSS: -1.979193
	BEST VAL LOSS:    -1.979193
	BEST VAL EPOCH:   8
EPOCH 9 8.145092010498047
BEST VAL RESULT. SAVING MODEL...
EPOCH 9 EVAL: 
	CURRENT VAL LOSS: -2.204110
	BEST VAL LOSS:    -2.204110
	BEST VAL EPOCH:   9
EPOCH 10 8.147375106811523
BEST VAL RESULT. SAVING MODEL...
EPOCH 10 EVAL: 
	CURRENT VAL LOSS: -2.449777
	BEST VAL LOSS:    -2.449777
	BEST VAL EPOCH:   10
EPOCH 11 8.13719367980957
BEST VAL RESULT. SAVING MODEL...
EPOCH 11 EVAL: 
	CURRENT VAL LOSS: -2.617168
	BEST VAL LOSS:    -2.617168
	BEST VAL EPOCH:   11
EPOCH 12 8.11971664428711
EPOCH 12 EVAL: 
	CURRENT VAL LOSS: -2.606070
	BEST VAL LOSS:    -2.617168
	BEST VAL EPOCH:   11
EPOCH 13 8.119979619979858
BEST VAL RESULT. SAVING MODEL...
EPOCH 13 EVAL: 
	CURRENT VAL LOSS: -2.733561
	BEST VAL LOSS:    -2.733561
	BEST VAL EPOCH:   13
EPOCH 14 8.15608024597168
BEST VAL RESULT. SAVING MODEL...
EPOCH 14 EVAL: 
	CURRENT VAL LOSS: -2.772089
	BEST VAL LOSS:    -2.772089
	BEST VAL EPOCH:   14
EPOCH 15 8.132006645202637
BEST VAL RESULT. SAVING MODEL...
EPOCH 15 EVAL: 
	CURRENT VAL LOSS: -2.786741
	BEST VAL LOSS:    -2.786741
	BEST VAL EPOCH:   15
EPOCH 16 8.137092351913452
BEST VAL RESULT. SAVING MODEL...
EPOCH 16 EVAL: 
	CURRENT VAL LOSS: -2.851275
	BEST VAL LOSS:    -2.851275
	BEST VAL EPOCH:   16
EPOCH 17 8.13918423652649
BEST VAL RESULT. SAVING MODEL...
EPOCH 17 EVAL: 
	CURRENT VAL LOSS: -2.917747
	BEST VAL LOSS:    -2.917747
	BEST VAL EPOCH:   17
EPOCH 18 8.130845546722412
BEST VAL RESULT. SAVING MODEL...
EPOCH 18 EVAL: 
	CURRENT VAL LOSS: -2.982407
	BEST VAL LOSS:    -2.982407
	BEST VAL EPOCH:   18
EPOCH 19 8.132466077804565
EPOCH 19 EVAL: 
	CURRENT VAL LOSS: -2.962745
	BEST VAL LOSS:    -2.982407
	BEST VAL EPOCH:   18
EPOCH 20 8.120028972625732
EPOCH 20 EVAL: 
	CURRENT VAL LOSS: -2.862601
	BEST VAL LOSS:    -2.982407
	BEST VAL EPOCH:   18
EPOCH 21 8.077448844909668
BEST VAL RESULT. SAVING MODEL...
EPOCH 21 EVAL: 
	CURRENT VAL LOSS: -3.028770
	BEST VAL LOSS:    -3.028770
	BEST VAL EPOCH:   21
EPOCH 22 8.118762731552124
BEST VAL RESULT. SAVING MODEL...
EPOCH 22 EVAL: 
	CURRENT VAL LOSS: -3.042424
	BEST VAL LOSS:    -3.042424
	BEST VAL EPOCH:   22
EPOCH 23 8.126769304275513
EPOCH 23 EVAL: 
	CURRENT VAL LOSS: -3.018664
	BEST VAL LOSS:    -3.042424
	BEST VAL EPOCH:   22
EPOCH 24 8.119834184646606
EPOCH 24 EVAL: 
	CURRENT VAL LOSS: -3.032255
	BEST VAL LOSS:    -3.042424
	BEST VAL EPOCH:   22
EPOCH 25 8.12346363067627
EPOCH 25 EVAL: 
	CURRENT VAL LOSS: -3.024681
	BEST VAL LOSS:    -3.042424
	BEST VAL EPOCH:   22
EPOCH 26 8.123986005783081
BEST VAL RESULT. SAVING MODEL...
EPOCH 26 EVAL: 
	CURRENT VAL LOSS: -3.053986
	BEST VAL LOSS:    -3.053986
	BEST VAL EPOCH:   26
EPOCH 27 8.13993239402771
EPOCH 27 EVAL: 
	CURRENT VAL LOSS: -2.999744
	BEST VAL LOSS:    -3.053986
	BEST VAL EPOCH:   26
EPOCH 28 8.119603633880615
BEST VAL RESULT. SAVING MODEL...
EPOCH 28 EVAL: 
	CURRENT VAL LOSS: -3.091985
	BEST VAL LOSS:    -3.091985
	BEST VAL EPOCH:   28
EPOCH 29 8.146538734436035
BEST VAL RESULT. SAVING MODEL...
EPOCH 29 EVAL: 
	CURRENT VAL LOSS: -3.094235
	BEST VAL LOSS:    -3.094235
	BEST VAL EPOCH:   29
EPOCH 30 8.153559923171997
BEST VAL RESULT. SAVING MODEL...
EPOCH 30 EVAL: 
	CURRENT VAL LOSS: -3.174147
	BEST VAL LOSS:    -3.174147
	BEST VAL EPOCH:   30
EPOCH 31 8.141011476516724
EPOCH 31 EVAL: 
	CURRENT VAL LOSS: -2.996926
	BEST VAL LOSS:    -3.174147
	BEST VAL EPOCH:   30
EPOCH 32 8.125495672225952
EPOCH 32 EVAL: 
	CURRENT VAL LOSS: -3.081545
	BEST VAL LOSS:    -3.174147
	BEST VAL EPOCH:   30
EPOCH 33 8.129344940185547
BEST VAL RESULT. SAVING MODEL...
EPOCH 33 EVAL: 
	CURRENT VAL LOSS: -3.177019
	BEST VAL LOSS:    -3.177019
	BEST VAL EPOCH:   33
EPOCH 34 8.143552303314209
EPOCH 34 EVAL: 
	CURRENT VAL LOSS: -3.135087
	BEST VAL LOSS:    -3.177019
	BEST VAL EPOCH:   33
EPOCH 35 8.117193937301636
EPOCH 35 EVAL: 
	CURRENT VAL LOSS: -3.111915
	BEST VAL LOSS:    -3.177019
	BEST VAL EPOCH:   33
EPOCH 36 8.127354383468628
EPOCH 36 EVAL: 
	CURRENT VAL LOSS: -3.138619
	BEST VAL LOSS:    -3.177019
	BEST VAL EPOCH:   33
EPOCH 37 8.131970643997192
BEST VAL RESULT. SAVING MODEL...
EPOCH 37 EVAL: 
	CURRENT VAL LOSS: -3.186508
	BEST VAL LOSS:    -3.186508
	BEST VAL EPOCH:   37
EPOCH 38 8.1366708278656
BEST VAL RESULT. SAVING MODEL...
EPOCH 38 EVAL: 
	CURRENT VAL LOSS: -3.189661
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 39 8.142291784286499
EPOCH 39 EVAL: 
	CURRENT VAL LOSS: -3.131736
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 40 8.109432220458984
EPOCH 40 EVAL: 
	CURRENT VAL LOSS: -3.181366
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 41 8.152116060256958
EPOCH 41 EVAL: 
	CURRENT VAL LOSS: -3.164144
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 42 8.144685983657837
EPOCH 42 EVAL: 
	CURRENT VAL LOSS: -3.157291
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 43 8.147284030914307
EPOCH 43 EVAL: 
	CURRENT VAL LOSS: -3.128713
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 44 8.155692100524902
EPOCH 44 EVAL: 
	CURRENT VAL LOSS: -3.167057
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 45 8.129456281661987
EPOCH 45 EVAL: 
	CURRENT VAL LOSS: -3.189143
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 46 8.139003992080688
EPOCH 46 EVAL: 
	CURRENT VAL LOSS: -3.168602
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 47 8.13172197341919
EPOCH 47 EVAL: 
	CURRENT VAL LOSS: -3.132560
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 48 8.126718997955322
EPOCH 48 EVAL: 
	CURRENT VAL LOSS: -3.184152
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 49 8.13449764251709
EPOCH 49 EVAL: 
	CURRENT VAL LOSS: -3.173085
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 50 8.119248867034912
EPOCH 50 EVAL: 
	CURRENT VAL LOSS: -3.130239
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
