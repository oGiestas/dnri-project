Using factor graph MLP encoder.
ENCODER:  RefMLPEncoder(
  (mlp1): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=160, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp2): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=512, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp3): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp4): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=768, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_out): Sequential(
    (0): Linear(in_features=256, out_features=256, bias=True)
    (1): ELU(alpha=1.0, inplace=True)
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ELU(alpha=1.0, inplace=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
)
Using learned recurrent interaction net decoder.
DECODER:  GraphRNNDecoder(
  (msg_fc1): ModuleList(
    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)
  )
  (msg_fc2): ModuleList(
    (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
  )
  (hidden_r): Linear(in_features=256, out_features=256, bias=False)
  (hidden_i): Linear(in_features=256, out_features=256, bias=False)
  (hidden_h): Linear(in_features=256, out_features=256, bias=False)
  (input_r): Linear(in_features=4, out_features=256, bias=True)
  (input_i): Linear(in_features=4, out_features=256, bias=True)
  (input_n): Linear(in_features=4, out_features=256, bias=True)
  (out_fc1): Linear(in_features=256, out_features=256, bias=True)
  (out_fc2): Linear(in_features=256, out_features=256, bias=True)
  (out_fc3): Linear(in_features=256, out_features=4, bias=True)
)
USING UNIFORM PRIOR
EPOCH 1 0
/mnt/aiongpfs/users/rgiesta/bsps6/dnri/dnri/models/decoders.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  hidden = torch.cuda.FloatTensor(inputs.size(0), inputs.size(2), self.msg_out_shape).fill_(0.)
BEST VAL RESULT. SAVING MODEL...
EPOCH 1 EVAL: 
	CURRENT VAL LOSS: 18.185092
	BEST VAL LOSS:    18.185092
	BEST VAL EPOCH:   1
EPOCH 2 8.25835371017456
BEST VAL RESULT. SAVING MODEL...
EPOCH 2 EVAL: 
	CURRENT VAL LOSS: 0.996109
	BEST VAL LOSS:    0.996109
	BEST VAL EPOCH:   2
EPOCH 3 7.373790264129639
BEST VAL RESULT. SAVING MODEL...
EPOCH 3 EVAL: 
	CURRENT VAL LOSS: 0.334928
	BEST VAL LOSS:    0.334928
	BEST VAL EPOCH:   3
EPOCH 4 7.37716817855835
BEST VAL RESULT. SAVING MODEL...
EPOCH 4 EVAL: 
	CURRENT VAL LOSS: 0.029252
	BEST VAL LOSS:    0.029252
	BEST VAL EPOCH:   4
EPOCH 5 7.353565692901611
BEST VAL RESULT. SAVING MODEL...
EPOCH 5 EVAL: 
	CURRENT VAL LOSS: -0.800907
	BEST VAL LOSS:    -0.800907
	BEST VAL EPOCH:   5
EPOCH 6 7.374667167663574
BEST VAL RESULT. SAVING MODEL...
EPOCH 6 EVAL: 
	CURRENT VAL LOSS: -1.326410
	BEST VAL LOSS:    -1.326410
	BEST VAL EPOCH:   6
EPOCH 7 7.40231466293335
BEST VAL RESULT. SAVING MODEL...
EPOCH 7 EVAL: 
	CURRENT VAL LOSS: -1.643463
	BEST VAL LOSS:    -1.643463
	BEST VAL EPOCH:   7
EPOCH 8 7.373786211013794
BEST VAL RESULT. SAVING MODEL...
EPOCH 8 EVAL: 
	CURRENT VAL LOSS: -1.731458
	BEST VAL LOSS:    -1.731458
	BEST VAL EPOCH:   8
EPOCH 9 7.351034164428711
BEST VAL RESULT. SAVING MODEL...
EPOCH 9 EVAL: 
	CURRENT VAL LOSS: -1.847232
	BEST VAL LOSS:    -1.847232
	BEST VAL EPOCH:   9
EPOCH 10 7.36193060874939
BEST VAL RESULT. SAVING MODEL...
EPOCH 10 EVAL: 
	CURRENT VAL LOSS: -2.084499
	BEST VAL LOSS:    -2.084499
	BEST VAL EPOCH:   10
EPOCH 11 7.40415358543396
BEST VAL RESULT. SAVING MODEL...
EPOCH 11 EVAL: 
	CURRENT VAL LOSS: -2.098753
	BEST VAL LOSS:    -2.098753
	BEST VAL EPOCH:   11
EPOCH 12 7.382670640945435
BEST VAL RESULT. SAVING MODEL...
EPOCH 12 EVAL: 
	CURRENT VAL LOSS: -2.272998
	BEST VAL LOSS:    -2.272998
	BEST VAL EPOCH:   12
EPOCH 13 7.363075256347656
EPOCH 13 EVAL: 
	CURRENT VAL LOSS: -2.207478
	BEST VAL LOSS:    -2.272998
	BEST VAL EPOCH:   12
EPOCH 14 7.342564105987549
BEST VAL RESULT. SAVING MODEL...
EPOCH 14 EVAL: 
	CURRENT VAL LOSS: -2.326049
	BEST VAL LOSS:    -2.326049
	BEST VAL EPOCH:   14
EPOCH 15 7.352643728256226
BEST VAL RESULT. SAVING MODEL...
EPOCH 15 EVAL: 
	CURRENT VAL LOSS: -2.393650
	BEST VAL LOSS:    -2.393650
	BEST VAL EPOCH:   15
EPOCH 16 7.3380045890808105
BEST VAL RESULT. SAVING MODEL...
EPOCH 16 EVAL: 
	CURRENT VAL LOSS: -2.451228
	BEST VAL LOSS:    -2.451228
	BEST VAL EPOCH:   16
EPOCH 17 7.342855215072632
EPOCH 17 EVAL: 
	CURRENT VAL LOSS: -2.298100
	BEST VAL LOSS:    -2.451228
	BEST VAL EPOCH:   16
EPOCH 18 7.319843769073486
EPOCH 18 EVAL: 
	CURRENT VAL LOSS: -2.445938
	BEST VAL LOSS:    -2.451228
	BEST VAL EPOCH:   16
EPOCH 19 7.3643834590911865
EPOCH 19 EVAL: 
	CURRENT VAL LOSS: -2.422660
	BEST VAL LOSS:    -2.451228
	BEST VAL EPOCH:   16
EPOCH 20 7.326735019683838
BEST VAL RESULT. SAVING MODEL...
EPOCH 20 EVAL: 
	CURRENT VAL LOSS: -2.537139
	BEST VAL LOSS:    -2.537139
	BEST VAL EPOCH:   20
EPOCH 21 7.358062505722046
BEST VAL RESULT. SAVING MODEL...
EPOCH 21 EVAL: 
	CURRENT VAL LOSS: -2.544259
	BEST VAL LOSS:    -2.544259
	BEST VAL EPOCH:   21
EPOCH 22 7.3390607833862305
EPOCH 22 EVAL: 
	CURRENT VAL LOSS: -2.534179
	BEST VAL LOSS:    -2.544259
	BEST VAL EPOCH:   21
EPOCH 23 7.390696048736572
EPOCH 23 EVAL: 
	CURRENT VAL LOSS: -2.512864
	BEST VAL LOSS:    -2.544259
	BEST VAL EPOCH:   21
EPOCH 24 7.3245766162872314
EPOCH 24 EVAL: 
	CURRENT VAL LOSS: -2.448785
	BEST VAL LOSS:    -2.544259
	BEST VAL EPOCH:   21
EPOCH 25 7.3200531005859375
EPOCH 25 EVAL: 
	CURRENT VAL LOSS: -2.528294
	BEST VAL LOSS:    -2.544259
	BEST VAL EPOCH:   21
EPOCH 26 7.334063529968262
EPOCH 26 EVAL: 
	CURRENT VAL LOSS: -2.458834
	BEST VAL LOSS:    -2.544259
	BEST VAL EPOCH:   21
EPOCH 27 7.346804141998291
EPOCH 27 EVAL: 
	CURRENT VAL LOSS: -2.397074
	BEST VAL LOSS:    -2.544259
	BEST VAL EPOCH:   21
EPOCH 28 7.3945653438568115
BEST VAL RESULT. SAVING MODEL...
EPOCH 28 EVAL: 
	CURRENT VAL LOSS: -2.610355
	BEST VAL LOSS:    -2.610355
	BEST VAL EPOCH:   28
EPOCH 29 7.3520708084106445
EPOCH 29 EVAL: 
	CURRENT VAL LOSS: -2.575670
	BEST VAL LOSS:    -2.610355
	BEST VAL EPOCH:   28
EPOCH 30 7.328271389007568
EPOCH 30 EVAL: 
	CURRENT VAL LOSS: -2.601263
	BEST VAL LOSS:    -2.610355
	BEST VAL EPOCH:   28
EPOCH 31 7.33899450302124
EPOCH 31 EVAL: 
	CURRENT VAL LOSS: -2.581315
	BEST VAL LOSS:    -2.610355
	BEST VAL EPOCH:   28
EPOCH 32 7.360613584518433
EPOCH 32 EVAL: 
	CURRENT VAL LOSS: -2.482100
	BEST VAL LOSS:    -2.610355
	BEST VAL EPOCH:   28
EPOCH 33 7.3351874351501465
EPOCH 33 EVAL: 
	CURRENT VAL LOSS: -2.439898
	BEST VAL LOSS:    -2.610355
	BEST VAL EPOCH:   28
EPOCH 34 7.370536804199219
EPOCH 34 EVAL: 
	CURRENT VAL LOSS: -2.590786
	BEST VAL LOSS:    -2.610355
	BEST VAL EPOCH:   28
EPOCH 35 7.361383676528931
BEST VAL RESULT. SAVING MODEL...
EPOCH 35 EVAL: 
	CURRENT VAL LOSS: -2.652520
	BEST VAL LOSS:    -2.652520
	BEST VAL EPOCH:   35
EPOCH 36 7.354347229003906
EPOCH 36 EVAL: 
	CURRENT VAL LOSS: -2.580925
	BEST VAL LOSS:    -2.652520
	BEST VAL EPOCH:   35
EPOCH 37 7.323741674423218
BEST VAL RESULT. SAVING MODEL...
EPOCH 37 EVAL: 
	CURRENT VAL LOSS: -2.687689
	BEST VAL LOSS:    -2.687689
	BEST VAL EPOCH:   37
EPOCH 38 7.3590333461761475
EPOCH 38 EVAL: 
	CURRENT VAL LOSS: -2.562023
	BEST VAL LOSS:    -2.687689
	BEST VAL EPOCH:   37
EPOCH 39 7.330838680267334
EPOCH 39 EVAL: 
	CURRENT VAL LOSS: -2.498110
	BEST VAL LOSS:    -2.687689
	BEST VAL EPOCH:   37
EPOCH 40 7.336967468261719
EPOCH 40 EVAL: 
	CURRENT VAL LOSS: -2.651117
	BEST VAL LOSS:    -2.687689
	BEST VAL EPOCH:   37
EPOCH 41 7.338052749633789
EPOCH 41 EVAL: 
	CURRENT VAL LOSS: -2.536612
	BEST VAL LOSS:    -2.687689
	BEST VAL EPOCH:   37
EPOCH 42 7.334968566894531
EPOCH 42 EVAL: 
	CURRENT VAL LOSS: -2.528282
	BEST VAL LOSS:    -2.687689
	BEST VAL EPOCH:   37
EPOCH 43 7.34415864944458
EPOCH 43 EVAL: 
	CURRENT VAL LOSS: -2.578415
	BEST VAL LOSS:    -2.687689
	BEST VAL EPOCH:   37
EPOCH 44 7.41076135635376
EPOCH 44 EVAL: 
	CURRENT VAL LOSS: -2.303451
	BEST VAL LOSS:    -2.687689
	BEST VAL EPOCH:   37
EPOCH 45 7.349932432174683
EPOCH 45 EVAL: 
	CURRENT VAL LOSS: -2.532805
	BEST VAL LOSS:    -2.687689
	BEST VAL EPOCH:   37
EPOCH 46 7.3508501052856445
EPOCH 46 EVAL: 
	CURRENT VAL LOSS: -2.539838
	BEST VAL LOSS:    -2.687689
	BEST VAL EPOCH:   37
EPOCH 47 7.371307134628296
EPOCH 47 EVAL: 
	CURRENT VAL LOSS: -2.499327
	BEST VAL LOSS:    -2.687689
	BEST VAL EPOCH:   37
EPOCH 48 7.342862367630005
BEST VAL RESULT. SAVING MODEL...
EPOCH 48 EVAL: 
	CURRENT VAL LOSS: -2.687694
	BEST VAL LOSS:    -2.687694
	BEST VAL EPOCH:   48
EPOCH 49 7.367963075637817
BEST VAL RESULT. SAVING MODEL...
EPOCH 49 EVAL: 
	CURRENT VAL LOSS: -2.713521
	BEST VAL LOSS:    -2.713521
	BEST VAL EPOCH:   49
EPOCH 50 7.34510064125061
BEST VAL RESULT. SAVING MODEL...
EPOCH 50 EVAL: 
	CURRENT VAL LOSS: -2.766922
	BEST VAL LOSS:    -2.766922
	BEST VAL EPOCH:   50
