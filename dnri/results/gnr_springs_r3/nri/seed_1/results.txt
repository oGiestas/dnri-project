Using factor graph MLP encoder.
ENCODER:  RefMLPEncoder(
  (mlp1): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=160, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp2): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=512, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp3): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp4): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=768, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_out): Sequential(
    (0): Linear(in_features=256, out_features=256, bias=True)
    (1): ELU(alpha=1.0, inplace=True)
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ELU(alpha=1.0, inplace=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
)
Using learned recurrent interaction net decoder.
DECODER:  GraphRNNDecoder(
  (msg_fc1): ModuleList(
    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)
  )
  (msg_fc2): ModuleList(
    (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
  )
  (hidden_r): Linear(in_features=256, out_features=256, bias=False)
  (hidden_i): Linear(in_features=256, out_features=256, bias=False)
  (hidden_h): Linear(in_features=256, out_features=256, bias=False)
  (input_r): Linear(in_features=4, out_features=256, bias=True)
  (input_i): Linear(in_features=4, out_features=256, bias=True)
  (input_n): Linear(in_features=4, out_features=256, bias=True)
  (out_fc1): Linear(in_features=256, out_features=256, bias=True)
  (out_fc2): Linear(in_features=256, out_features=256, bias=True)
  (out_fc3): Linear(in_features=256, out_features=4, bias=True)
)
USING UNIFORM PRIOR
EPOCH 1 0
/mnt/aiongpfs/users/rgiesta/bsps6/dnri/dnri/models/decoders.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  hidden = torch.cuda.FloatTensor(inputs.size(0), inputs.size(2), self.msg_out_shape).fill_(0.)
BEST VAL RESULT. SAVING MODEL...
EPOCH 1 EVAL: 
	CURRENT VAL LOSS: 8.636335
	BEST VAL LOSS:    8.636335
	BEST VAL EPOCH:   1
EPOCH 2 8.419644594192505
BEST VAL RESULT. SAVING MODEL...
EPOCH 2 EVAL: 
	CURRENT VAL LOSS: 1.013307
	BEST VAL LOSS:    1.013307
	BEST VAL EPOCH:   2
EPOCH 3 7.419713020324707
BEST VAL RESULT. SAVING MODEL...
EPOCH 3 EVAL: 
	CURRENT VAL LOSS: 0.378773
	BEST VAL LOSS:    0.378773
	BEST VAL EPOCH:   3
EPOCH 4 7.373413324356079
BEST VAL RESULT. SAVING MODEL...
EPOCH 4 EVAL: 
	CURRENT VAL LOSS: -0.473438
	BEST VAL LOSS:    -0.473438
	BEST VAL EPOCH:   4
EPOCH 5 7.380944013595581
BEST VAL RESULT. SAVING MODEL...
EPOCH 5 EVAL: 
	CURRENT VAL LOSS: -0.981224
	BEST VAL LOSS:    -0.981224
	BEST VAL EPOCH:   5
EPOCH 6 7.391263961791992
EPOCH 6 EVAL: 
	CURRENT VAL LOSS: -0.841841
	BEST VAL LOSS:    -0.981224
	BEST VAL EPOCH:   5
EPOCH 7 7.367290496826172
BEST VAL RESULT. SAVING MODEL...
EPOCH 7 EVAL: 
	CURRENT VAL LOSS: -1.452591
	BEST VAL LOSS:    -1.452591
	BEST VAL EPOCH:   7
EPOCH 8 7.372002601623535
EPOCH 8 EVAL: 
	CURRENT VAL LOSS: -1.401348
	BEST VAL LOSS:    -1.452591
	BEST VAL EPOCH:   7
EPOCH 9 7.3525309562683105
BEST VAL RESULT. SAVING MODEL...
EPOCH 9 EVAL: 
	CURRENT VAL LOSS: -1.688944
	BEST VAL LOSS:    -1.688944
	BEST VAL EPOCH:   9
EPOCH 10 7.3893468379974365
EPOCH 10 EVAL: 
	CURRENT VAL LOSS: -1.657210
	BEST VAL LOSS:    -1.688944
	BEST VAL EPOCH:   9
EPOCH 11 7.379723787307739
BEST VAL RESULT. SAVING MODEL...
EPOCH 11 EVAL: 
	CURRENT VAL LOSS: -1.831429
	BEST VAL LOSS:    -1.831429
	BEST VAL EPOCH:   11
EPOCH 12 7.3547279834747314
EPOCH 12 EVAL: 
	CURRENT VAL LOSS: -1.777571
	BEST VAL LOSS:    -1.831429
	BEST VAL EPOCH:   11
EPOCH 13 7.374709129333496
BEST VAL RESULT. SAVING MODEL...
EPOCH 13 EVAL: 
	CURRENT VAL LOSS: -1.911762
	BEST VAL LOSS:    -1.911762
	BEST VAL EPOCH:   13
EPOCH 14 7.40090012550354
BEST VAL RESULT. SAVING MODEL...
EPOCH 14 EVAL: 
	CURRENT VAL LOSS: -2.036501
	BEST VAL LOSS:    -2.036501
	BEST VAL EPOCH:   14
EPOCH 15 7.358835935592651
BEST VAL RESULT. SAVING MODEL...
EPOCH 15 EVAL: 
	CURRENT VAL LOSS: -2.202805
	BEST VAL LOSS:    -2.202805
	BEST VAL EPOCH:   15
EPOCH 16 7.370304822921753
BEST VAL RESULT. SAVING MODEL...
EPOCH 16 EVAL: 
	CURRENT VAL LOSS: -2.432619
	BEST VAL LOSS:    -2.432619
	BEST VAL EPOCH:   16
EPOCH 17 7.353458642959595
EPOCH 17 EVAL: 
	CURRENT VAL LOSS: -2.263002
	BEST VAL LOSS:    -2.432619
	BEST VAL EPOCH:   16
EPOCH 18 7.375217914581299
EPOCH 18 EVAL: 
	CURRENT VAL LOSS: -2.300850
	BEST VAL LOSS:    -2.432619
	BEST VAL EPOCH:   16
EPOCH 19 7.404871940612793
BEST VAL RESULT. SAVING MODEL...
EPOCH 19 EVAL: 
	CURRENT VAL LOSS: -2.510842
	BEST VAL LOSS:    -2.510842
	BEST VAL EPOCH:   19
EPOCH 20 7.362637281417847
EPOCH 20 EVAL: 
	CURRENT VAL LOSS: -2.334718
	BEST VAL LOSS:    -2.510842
	BEST VAL EPOCH:   19
EPOCH 21 7.351036071777344
EPOCH 21 EVAL: 
	CURRENT VAL LOSS: -2.461120
	BEST VAL LOSS:    -2.510842
	BEST VAL EPOCH:   19
EPOCH 22 7.3687474727630615
EPOCH 22 EVAL: 
	CURRENT VAL LOSS: -2.485513
	BEST VAL LOSS:    -2.510842
	BEST VAL EPOCH:   19
EPOCH 23 7.373372793197632
EPOCH 23 EVAL: 
	CURRENT VAL LOSS: -2.458213
	BEST VAL LOSS:    -2.510842
	BEST VAL EPOCH:   19
EPOCH 24 7.365837574005127
EPOCH 24 EVAL: 
	CURRENT VAL LOSS: -2.496095
	BEST VAL LOSS:    -2.510842
	BEST VAL EPOCH:   19
EPOCH 25 7.3640735149383545
EPOCH 25 EVAL: 
	CURRENT VAL LOSS: -2.490194
	BEST VAL LOSS:    -2.510842
	BEST VAL EPOCH:   19
EPOCH 26 7.355515003204346
BEST VAL RESULT. SAVING MODEL...
EPOCH 26 EVAL: 
	CURRENT VAL LOSS: -2.569966
	BEST VAL LOSS:    -2.569966
	BEST VAL EPOCH:   26
EPOCH 27 7.344993352890015
EPOCH 27 EVAL: 
	CURRENT VAL LOSS: -2.510739
	BEST VAL LOSS:    -2.569966
	BEST VAL EPOCH:   26
EPOCH 28 7.342888355255127
EPOCH 28 EVAL: 
	CURRENT VAL LOSS: -2.448731
	BEST VAL LOSS:    -2.569966
	BEST VAL EPOCH:   26
EPOCH 29 7.339315176010132
EPOCH 29 EVAL: 
	CURRENT VAL LOSS: -2.538679
	BEST VAL LOSS:    -2.569966
	BEST VAL EPOCH:   26
EPOCH 30 7.357157468795776
EPOCH 30 EVAL: 
	CURRENT VAL LOSS: -2.518613
	BEST VAL LOSS:    -2.569966
	BEST VAL EPOCH:   26
EPOCH 31 7.33183741569519
EPOCH 31 EVAL: 
	CURRENT VAL LOSS: -2.527259
	BEST VAL LOSS:    -2.569966
	BEST VAL EPOCH:   26
EPOCH 32 7.3446364402771
EPOCH 32 EVAL: 
	CURRENT VAL LOSS: -2.456659
	BEST VAL LOSS:    -2.569966
	BEST VAL EPOCH:   26
EPOCH 33 7.318758964538574
EPOCH 33 EVAL: 
	CURRENT VAL LOSS: -2.454150
	BEST VAL LOSS:    -2.569966
	BEST VAL EPOCH:   26
EPOCH 34 7.333524465560913
BEST VAL RESULT. SAVING MODEL...
EPOCH 34 EVAL: 
	CURRENT VAL LOSS: -2.635308
	BEST VAL LOSS:    -2.635308
	BEST VAL EPOCH:   34
EPOCH 35 7.3662238121032715
EPOCH 35 EVAL: 
	CURRENT VAL LOSS: -2.620137
	BEST VAL LOSS:    -2.635308
	BEST VAL EPOCH:   34
EPOCH 36 7.35727858543396
EPOCH 36 EVAL: 
	CURRENT VAL LOSS: -2.623843
	BEST VAL LOSS:    -2.635308
	BEST VAL EPOCH:   34
EPOCH 37 7.331993579864502
EPOCH 37 EVAL: 
	CURRENT VAL LOSS: -2.563021
	BEST VAL LOSS:    -2.635308
	BEST VAL EPOCH:   34
EPOCH 38 7.3438720703125
EPOCH 38 EVAL: 
	CURRENT VAL LOSS: -2.443245
	BEST VAL LOSS:    -2.635308
	BEST VAL EPOCH:   34
EPOCH 39 7.372116804122925
EPOCH 39 EVAL: 
	CURRENT VAL LOSS: -2.456834
	BEST VAL LOSS:    -2.635308
	BEST VAL EPOCH:   34
EPOCH 40 7.327367305755615
EPOCH 40 EVAL: 
	CURRENT VAL LOSS: -2.500287
	BEST VAL LOSS:    -2.635308
	BEST VAL EPOCH:   34
EPOCH 41 7.300601005554199
EPOCH 41 EVAL: 
	CURRENT VAL LOSS: -2.579861
	BEST VAL LOSS:    -2.635308
	BEST VAL EPOCH:   34
EPOCH 42 7.341876029968262
BEST VAL RESULT. SAVING MODEL...
EPOCH 42 EVAL: 
	CURRENT VAL LOSS: -2.698785
	BEST VAL LOSS:    -2.698785
	BEST VAL EPOCH:   42
EPOCH 43 7.355577707290649
EPOCH 43 EVAL: 
	CURRENT VAL LOSS: -2.670403
	BEST VAL LOSS:    -2.698785
	BEST VAL EPOCH:   42
EPOCH 44 7.334033012390137
EPOCH 44 EVAL: 
	CURRENT VAL LOSS: -2.465851
	BEST VAL LOSS:    -2.698785
	BEST VAL EPOCH:   42
EPOCH 45 7.314377069473267
EPOCH 45 EVAL: 
	CURRENT VAL LOSS: -2.633758
	BEST VAL LOSS:    -2.698785
	BEST VAL EPOCH:   42
EPOCH 46 7.350473642349243
EPOCH 46 EVAL: 
	CURRENT VAL LOSS: -2.611664
	BEST VAL LOSS:    -2.698785
	BEST VAL EPOCH:   42
EPOCH 47 7.32604455947876
EPOCH 47 EVAL: 
	CURRENT VAL LOSS: -2.671700
	BEST VAL LOSS:    -2.698785
	BEST VAL EPOCH:   42
EPOCH 48 7.348747968673706
EPOCH 48 EVAL: 
	CURRENT VAL LOSS: -2.687786
	BEST VAL LOSS:    -2.698785
	BEST VAL EPOCH:   42
EPOCH 49 7.333706378936768
EPOCH 49 EVAL: 
	CURRENT VAL LOSS: -2.506694
	BEST VAL LOSS:    -2.698785
	BEST VAL EPOCH:   42
EPOCH 50 7.377512454986572
EPOCH 50 EVAL: 
	CURRENT VAL LOSS: -2.638179
	BEST VAL LOSS:    -2.698785
	BEST VAL EPOCH:   42
