Using factor graph MLP encoder.
ENCODER:  RefMLPEncoder(
  (mlp1): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=160, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp2): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=512, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp3): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp4): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=768, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_out): Sequential(
    (0): Linear(in_features=256, out_features=256, bias=True)
    (1): ELU(alpha=1.0, inplace=True)
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ELU(alpha=1.0, inplace=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
)
Using learned recurrent interaction net decoder.
DECODER:  GraphRNNDecoder(
  (msg_fc1): ModuleList(
    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)
  )
  (msg_fc2): ModuleList(
    (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
  )
  (hidden_r): Linear(in_features=256, out_features=256, bias=False)
  (hidden_i): Linear(in_features=256, out_features=256, bias=False)
  (hidden_h): Linear(in_features=256, out_features=256, bias=False)
  (input_r): Linear(in_features=4, out_features=256, bias=True)
  (input_i): Linear(in_features=4, out_features=256, bias=True)
  (input_n): Linear(in_features=4, out_features=256, bias=True)
  (out_fc1): Linear(in_features=256, out_features=256, bias=True)
  (out_fc2): Linear(in_features=256, out_features=256, bias=True)
  (out_fc3): Linear(in_features=256, out_features=4, bias=True)
)
USING UNIFORM PRIOR
EPOCH 1 0
/mnt/aiongpfs/users/rgiesta/bsps6/dnri/dnri/models/decoders.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  hidden = torch.cuda.FloatTensor(inputs.size(0), inputs.size(2), self.msg_out_shape).fill_(0.)
BEST VAL RESULT. SAVING MODEL...
EPOCH 1 EVAL: 
	CURRENT VAL LOSS: 30.057746
	BEST VAL LOSS:    30.057746
	BEST VAL EPOCH:   1
EPOCH 2 8.61652946472168
BEST VAL RESULT. SAVING MODEL...
EPOCH 2 EVAL: 
	CURRENT VAL LOSS: 2.866694
	BEST VAL LOSS:    2.866694
	BEST VAL EPOCH:   2
EPOCH 3 7.674344778060913
BEST VAL RESULT. SAVING MODEL...
EPOCH 3 EVAL: 
	CURRENT VAL LOSS: 0.864810
	BEST VAL LOSS:    0.864810
	BEST VAL EPOCH:   3
EPOCH 4 7.676589012145996
BEST VAL RESULT. SAVING MODEL...
EPOCH 4 EVAL: 
	CURRENT VAL LOSS: 0.522227
	BEST VAL LOSS:    0.522227
	BEST VAL EPOCH:   4
EPOCH 5 7.648343324661255
BEST VAL RESULT. SAVING MODEL...
EPOCH 5 EVAL: 
	CURRENT VAL LOSS: 0.113533
	BEST VAL LOSS:    0.113533
	BEST VAL EPOCH:   5
EPOCH 6 7.673854351043701
BEST VAL RESULT. SAVING MODEL...
EPOCH 6 EVAL: 
	CURRENT VAL LOSS: -0.301235
	BEST VAL LOSS:    -0.301235
	BEST VAL EPOCH:   6
EPOCH 7 7.6346611976623535
BEST VAL RESULT. SAVING MODEL...
EPOCH 7 EVAL: 
	CURRENT VAL LOSS: -0.517874
	BEST VAL LOSS:    -0.517874
	BEST VAL EPOCH:   7
EPOCH 8 7.648865699768066
EPOCH 8 EVAL: 
	CURRENT VAL LOSS: -0.479566
	BEST VAL LOSS:    -0.517874
	BEST VAL EPOCH:   7
EPOCH 9 7.637340784072876
EPOCH 9 EVAL: 
	CURRENT VAL LOSS: -0.333294
	BEST VAL LOSS:    -0.517874
	BEST VAL EPOCH:   7
EPOCH 10 7.63893985748291
BEST VAL RESULT. SAVING MODEL...
EPOCH 10 EVAL: 
	CURRENT VAL LOSS: -0.897361
	BEST VAL LOSS:    -0.897361
	BEST VAL EPOCH:   10
EPOCH 11 7.640366077423096
BEST VAL RESULT. SAVING MODEL...
EPOCH 11 EVAL: 
	CURRENT VAL LOSS: -1.214886
	BEST VAL LOSS:    -1.214886
	BEST VAL EPOCH:   11
EPOCH 12 7.663649082183838
BEST VAL RESULT. SAVING MODEL...
EPOCH 12 EVAL: 
	CURRENT VAL LOSS: -1.477563
	BEST VAL LOSS:    -1.477563
	BEST VAL EPOCH:   12
EPOCH 13 7.655104398727417
EPOCH 13 EVAL: 
	CURRENT VAL LOSS: -1.334509
	BEST VAL LOSS:    -1.477563
	BEST VAL EPOCH:   12
EPOCH 14 7.632094144821167
BEST VAL RESULT. SAVING MODEL...
EPOCH 14 EVAL: 
	CURRENT VAL LOSS: -1.863776
	BEST VAL LOSS:    -1.863776
	BEST VAL EPOCH:   14
EPOCH 15 7.6519529819488525
BEST VAL RESULT. SAVING MODEL...
EPOCH 15 EVAL: 
	CURRENT VAL LOSS: -1.865845
	BEST VAL LOSS:    -1.865845
	BEST VAL EPOCH:   15
EPOCH 16 7.67061972618103
BEST VAL RESULT. SAVING MODEL...
EPOCH 16 EVAL: 
	CURRENT VAL LOSS: -2.023734
	BEST VAL LOSS:    -2.023734
	BEST VAL EPOCH:   16
EPOCH 17 7.648802995681763
EPOCH 17 EVAL: 
	CURRENT VAL LOSS: -1.975142
	BEST VAL LOSS:    -2.023734
	BEST VAL EPOCH:   16
EPOCH 18 7.618377447128296
BEST VAL RESULT. SAVING MODEL...
EPOCH 18 EVAL: 
	CURRENT VAL LOSS: -2.024550
	BEST VAL LOSS:    -2.024550
	BEST VAL EPOCH:   18
EPOCH 19 7.636503219604492
BEST VAL RESULT. SAVING MODEL...
EPOCH 19 EVAL: 
	CURRENT VAL LOSS: -2.161363
	BEST VAL LOSS:    -2.161363
	BEST VAL EPOCH:   19
EPOCH 20 7.662046432495117
BEST VAL RESULT. SAVING MODEL...
EPOCH 20 EVAL: 
	CURRENT VAL LOSS: -2.200848
	BEST VAL LOSS:    -2.200848
	BEST VAL EPOCH:   20
EPOCH 21 7.651540040969849
EPOCH 21 EVAL: 
	CURRENT VAL LOSS: -2.137095
	BEST VAL LOSS:    -2.200848
	BEST VAL EPOCH:   20
EPOCH 22 7.628905773162842
BEST VAL RESULT. SAVING MODEL...
EPOCH 22 EVAL: 
	CURRENT VAL LOSS: -2.220109
	BEST VAL LOSS:    -2.220109
	BEST VAL EPOCH:   22
EPOCH 23 7.653356552124023
EPOCH 23 EVAL: 
	CURRENT VAL LOSS: -2.190789
	BEST VAL LOSS:    -2.220109
	BEST VAL EPOCH:   22
EPOCH 24 7.629133701324463
EPOCH 24 EVAL: 
	CURRENT VAL LOSS: -2.202459
	BEST VAL LOSS:    -2.220109
	BEST VAL EPOCH:   22
EPOCH 25 7.643812894821167
BEST VAL RESULT. SAVING MODEL...
EPOCH 25 EVAL: 
	CURRENT VAL LOSS: -2.392427
	BEST VAL LOSS:    -2.392427
	BEST VAL EPOCH:   25
EPOCH 26 7.642530202865601
EPOCH 26 EVAL: 
	CURRENT VAL LOSS: -2.318625
	BEST VAL LOSS:    -2.392427
	BEST VAL EPOCH:   25
EPOCH 27 7.645514249801636
EPOCH 27 EVAL: 
	CURRENT VAL LOSS: -2.333652
	BEST VAL LOSS:    -2.392427
	BEST VAL EPOCH:   25
EPOCH 28 7.650676488876343
BEST VAL RESULT. SAVING MODEL...
EPOCH 28 EVAL: 
	CURRENT VAL LOSS: -2.428464
	BEST VAL LOSS:    -2.428464
	BEST VAL EPOCH:   28
EPOCH 29 7.672986745834351
EPOCH 29 EVAL: 
	CURRENT VAL LOSS: -2.327953
	BEST VAL LOSS:    -2.428464
	BEST VAL EPOCH:   28
EPOCH 30 7.635918855667114
EPOCH 30 EVAL: 
	CURRENT VAL LOSS: -2.270797
	BEST VAL LOSS:    -2.428464
	BEST VAL EPOCH:   28
EPOCH 31 7.638022422790527
EPOCH 31 EVAL: 
	CURRENT VAL LOSS: -2.416459
	BEST VAL LOSS:    -2.428464
	BEST VAL EPOCH:   28
EPOCH 32 7.624273300170898
EPOCH 32 EVAL: 
	CURRENT VAL LOSS: -2.351304
	BEST VAL LOSS:    -2.428464
	BEST VAL EPOCH:   28
EPOCH 33 7.641803026199341
BEST VAL RESULT. SAVING MODEL...
EPOCH 33 EVAL: 
	CURRENT VAL LOSS: -2.437919
	BEST VAL LOSS:    -2.437919
	BEST VAL EPOCH:   33
EPOCH 34 7.641688108444214
BEST VAL RESULT. SAVING MODEL...
EPOCH 34 EVAL: 
	CURRENT VAL LOSS: -2.575372
	BEST VAL LOSS:    -2.575372
	BEST VAL EPOCH:   34
EPOCH 35 7.639824867248535
BEST VAL RESULT. SAVING MODEL...
EPOCH 35 EVAL: 
	CURRENT VAL LOSS: -2.597060
	BEST VAL LOSS:    -2.597060
	BEST VAL EPOCH:   35
EPOCH 36 7.644816160202026
EPOCH 36 EVAL: 
	CURRENT VAL LOSS: -2.420507
	BEST VAL LOSS:    -2.597060
	BEST VAL EPOCH:   35
EPOCH 37 7.635483026504517
EPOCH 37 EVAL: 
	CURRENT VAL LOSS: -2.590892
	BEST VAL LOSS:    -2.597060
	BEST VAL EPOCH:   35
EPOCH 38 7.6341612339019775
BEST VAL RESULT. SAVING MODEL...
EPOCH 38 EVAL: 
	CURRENT VAL LOSS: -2.606293
	BEST VAL LOSS:    -2.606293
	BEST VAL EPOCH:   38
EPOCH 39 7.645497560501099
EPOCH 39 EVAL: 
	CURRENT VAL LOSS: -2.232228
	BEST VAL LOSS:    -2.606293
	BEST VAL EPOCH:   38
EPOCH 40 7.637195825576782
EPOCH 40 EVAL: 
	CURRENT VAL LOSS: -2.527203
	BEST VAL LOSS:    -2.606293
	BEST VAL EPOCH:   38
EPOCH 41 7.641204833984375
EPOCH 41 EVAL: 
	CURRENT VAL LOSS: -2.540707
	BEST VAL LOSS:    -2.606293
	BEST VAL EPOCH:   38
EPOCH 42 7.629488945007324
EPOCH 42 EVAL: 
	CURRENT VAL LOSS: -2.566093
	BEST VAL LOSS:    -2.606293
	BEST VAL EPOCH:   38
EPOCH 43 7.65263819694519
EPOCH 43 EVAL: 
	CURRENT VAL LOSS: -2.390085
	BEST VAL LOSS:    -2.606293
	BEST VAL EPOCH:   38
EPOCH 44 7.639387845993042
EPOCH 44 EVAL: 
	CURRENT VAL LOSS: -2.513048
	BEST VAL LOSS:    -2.606293
	BEST VAL EPOCH:   38
EPOCH 45 7.639896392822266
BEST VAL RESULT. SAVING MODEL...
EPOCH 45 EVAL: 
	CURRENT VAL LOSS: -2.632380
	BEST VAL LOSS:    -2.632380
	BEST VAL EPOCH:   45
EPOCH 46 7.640209913253784
EPOCH 46 EVAL: 
	CURRENT VAL LOSS: -2.552139
	BEST VAL LOSS:    -2.632380
	BEST VAL EPOCH:   45
EPOCH 47 7.625548362731934
BEST VAL RESULT. SAVING MODEL...
EPOCH 47 EVAL: 
	CURRENT VAL LOSS: -2.672166
	BEST VAL LOSS:    -2.672166
	BEST VAL EPOCH:   47
EPOCH 48 7.635731935501099
BEST VAL RESULT. SAVING MODEL...
EPOCH 48 EVAL: 
	CURRENT VAL LOSS: -2.673491
	BEST VAL LOSS:    -2.673491
	BEST VAL EPOCH:   48
EPOCH 49 7.651714563369751
BEST VAL RESULT. SAVING MODEL...
EPOCH 49 EVAL: 
	CURRENT VAL LOSS: -2.690790
	BEST VAL LOSS:    -2.690790
	BEST VAL EPOCH:   49
EPOCH 50 7.642950534820557
BEST VAL RESULT. SAVING MODEL...
EPOCH 50 EVAL: 
	CURRENT VAL LOSS: -2.699087
	BEST VAL LOSS:    -2.699087
	BEST VAL EPOCH:   50
