Using factor graph MLP encoder.
ENCODER:  RefMLPEncoder(
  (mlp1): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=160, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp2): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=512, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp3): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp4): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=768, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_out): Sequential(
    (0): Linear(in_features=256, out_features=256, bias=True)
    (1): ELU(alpha=1.0, inplace=True)
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ELU(alpha=1.0, inplace=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
)
Using learned recurrent interaction net decoder.
DECODER:  GraphRNNDecoder(
  (msg_fc1): ModuleList(
    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)
  )
  (msg_fc2): ModuleList(
    (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
  )
  (hidden_r): Linear(in_features=256, out_features=256, bias=False)
  (hidden_i): Linear(in_features=256, out_features=256, bias=False)
  (hidden_h): Linear(in_features=256, out_features=256, bias=False)
  (input_r): Linear(in_features=4, out_features=256, bias=True)
  (input_i): Linear(in_features=4, out_features=256, bias=True)
  (input_n): Linear(in_features=4, out_features=256, bias=True)
  (out_fc1): Linear(in_features=256, out_features=256, bias=True)
  (out_fc2): Linear(in_features=256, out_features=256, bias=True)
  (out_fc3): Linear(in_features=256, out_features=4, bias=True)
)
USING UNIFORM PRIOR
EPOCH 1 0
/mnt/aiongpfs/users/rgiesta/bsps6/dnri/dnri/models/decoders.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  hidden = torch.cuda.FloatTensor(inputs.size(0), inputs.size(2), self.msg_out_shape).fill_(0.)
BEST VAL RESULT. SAVING MODEL...
EPOCH 1 EVAL: 
	CURRENT VAL LOSS: 5.571706
	BEST VAL LOSS:    5.571706
	BEST VAL EPOCH:   1
EPOCH 2 12.143194198608398
BEST VAL RESULT. SAVING MODEL...
EPOCH 2 EVAL: 
	CURRENT VAL LOSS: -0.769393
	BEST VAL LOSS:    -0.769393
	BEST VAL EPOCH:   2
EPOCH 3 11.186936140060425
BEST VAL RESULT. SAVING MODEL...
EPOCH 3 EVAL: 
	CURRENT VAL LOSS: -0.970616
	BEST VAL LOSS:    -0.970616
	BEST VAL EPOCH:   3
EPOCH 4 11.184048652648926
BEST VAL RESULT. SAVING MODEL...
EPOCH 4 EVAL: 
	CURRENT VAL LOSS: -1.127949
	BEST VAL LOSS:    -1.127949
	BEST VAL EPOCH:   4
EPOCH 5 11.14741039276123
BEST VAL RESULT. SAVING MODEL...
EPOCH 5 EVAL: 
	CURRENT VAL LOSS: -1.513557
	BEST VAL LOSS:    -1.513557
	BEST VAL EPOCH:   5
EPOCH 6 11.136197328567505
BEST VAL RESULT. SAVING MODEL...
EPOCH 6 EVAL: 
	CURRENT VAL LOSS: -1.901017
	BEST VAL LOSS:    -1.901017
	BEST VAL EPOCH:   6
EPOCH 7 11.125759363174438
EPOCH 7 EVAL: 
	CURRENT VAL LOSS: -1.616182
	BEST VAL LOSS:    -1.901017
	BEST VAL EPOCH:   6
EPOCH 8 11.102165699005127
BEST VAL RESULT. SAVING MODEL...
EPOCH 8 EVAL: 
	CURRENT VAL LOSS: -1.979193
	BEST VAL LOSS:    -1.979193
	BEST VAL EPOCH:   8
EPOCH 9 11.119366884231567
BEST VAL RESULT. SAVING MODEL...
EPOCH 9 EVAL: 
	CURRENT VAL LOSS: -2.204110
	BEST VAL LOSS:    -2.204110
	BEST VAL EPOCH:   9
EPOCH 10 11.1196928024292
BEST VAL RESULT. SAVING MODEL...
EPOCH 10 EVAL: 
	CURRENT VAL LOSS: -2.449777
	BEST VAL LOSS:    -2.449777
	BEST VAL EPOCH:   10
EPOCH 11 11.116265535354614
BEST VAL RESULT. SAVING MODEL...
EPOCH 11 EVAL: 
	CURRENT VAL LOSS: -2.617168
	BEST VAL LOSS:    -2.617168
	BEST VAL EPOCH:   11
EPOCH 12 11.120397567749023
EPOCH 12 EVAL: 
	CURRENT VAL LOSS: -2.606070
	BEST VAL LOSS:    -2.617168
	BEST VAL EPOCH:   11
EPOCH 13 11.100433349609375
BEST VAL RESULT. SAVING MODEL...
EPOCH 13 EVAL: 
	CURRENT VAL LOSS: -2.733561
	BEST VAL LOSS:    -2.733561
	BEST VAL EPOCH:   13
EPOCH 14 11.097172498703003
BEST VAL RESULT. SAVING MODEL...
EPOCH 14 EVAL: 
	CURRENT VAL LOSS: -2.772089
	BEST VAL LOSS:    -2.772089
	BEST VAL EPOCH:   14
EPOCH 15 11.081840515136719
BEST VAL RESULT. SAVING MODEL...
EPOCH 15 EVAL: 
	CURRENT VAL LOSS: -2.786741
	BEST VAL LOSS:    -2.786741
	BEST VAL EPOCH:   15
EPOCH 16 11.078453779220581
BEST VAL RESULT. SAVING MODEL...
EPOCH 16 EVAL: 
	CURRENT VAL LOSS: -2.851275
	BEST VAL LOSS:    -2.851275
	BEST VAL EPOCH:   16
EPOCH 17 11.060482501983643
BEST VAL RESULT. SAVING MODEL...
EPOCH 17 EVAL: 
	CURRENT VAL LOSS: -2.917747
	BEST VAL LOSS:    -2.917747
	BEST VAL EPOCH:   17
EPOCH 18 11.04671025276184
BEST VAL RESULT. SAVING MODEL...
EPOCH 18 EVAL: 
	CURRENT VAL LOSS: -2.982407
	BEST VAL LOSS:    -2.982407
	BEST VAL EPOCH:   18
EPOCH 19 11.066627025604248
EPOCH 19 EVAL: 
	CURRENT VAL LOSS: -2.962745
	BEST VAL LOSS:    -2.982407
	BEST VAL EPOCH:   18
EPOCH 20 11.063106298446655
EPOCH 20 EVAL: 
	CURRENT VAL LOSS: -2.862601
	BEST VAL LOSS:    -2.982407
	BEST VAL EPOCH:   18
EPOCH 21 11.036518335342407
BEST VAL RESULT. SAVING MODEL...
EPOCH 21 EVAL: 
	CURRENT VAL LOSS: -3.028770
	BEST VAL LOSS:    -3.028770
	BEST VAL EPOCH:   21
EPOCH 22 11.052845239639282
BEST VAL RESULT. SAVING MODEL...
EPOCH 22 EVAL: 
	CURRENT VAL LOSS: -3.042424
	BEST VAL LOSS:    -3.042424
	BEST VAL EPOCH:   22
EPOCH 23 11.062070846557617
EPOCH 23 EVAL: 
	CURRENT VAL LOSS: -3.018664
	BEST VAL LOSS:    -3.042424
	BEST VAL EPOCH:   22
EPOCH 24 11.040980100631714
EPOCH 24 EVAL: 
	CURRENT VAL LOSS: -3.032255
	BEST VAL LOSS:    -3.042424
	BEST VAL EPOCH:   22
EPOCH 25 11.026015043258667
EPOCH 25 EVAL: 
	CURRENT VAL LOSS: -3.024681
	BEST VAL LOSS:    -3.042424
	BEST VAL EPOCH:   22
EPOCH 26 10.955381631851196
BEST VAL RESULT. SAVING MODEL...
EPOCH 26 EVAL: 
	CURRENT VAL LOSS: -3.053986
	BEST VAL LOSS:    -3.053986
	BEST VAL EPOCH:   26
EPOCH 27 10.938746690750122
EPOCH 27 EVAL: 
	CURRENT VAL LOSS: -2.999744
	BEST VAL LOSS:    -3.053986
	BEST VAL EPOCH:   26
EPOCH 28 10.925001382827759
BEST VAL RESULT. SAVING MODEL...
EPOCH 28 EVAL: 
	CURRENT VAL LOSS: -3.091985
	BEST VAL LOSS:    -3.091985
	BEST VAL EPOCH:   28
EPOCH 29 10.940181732177734
BEST VAL RESULT. SAVING MODEL...
EPOCH 29 EVAL: 
	CURRENT VAL LOSS: -3.094235
	BEST VAL LOSS:    -3.094235
	BEST VAL EPOCH:   29
EPOCH 30 10.930887222290039
BEST VAL RESULT. SAVING MODEL...
EPOCH 30 EVAL: 
	CURRENT VAL LOSS: -3.174147
	BEST VAL LOSS:    -3.174147
	BEST VAL EPOCH:   30
EPOCH 31 10.942039728164673
EPOCH 31 EVAL: 
	CURRENT VAL LOSS: -2.996926
	BEST VAL LOSS:    -3.174147
	BEST VAL EPOCH:   30
EPOCH 32 10.921922445297241
EPOCH 32 EVAL: 
	CURRENT VAL LOSS: -3.081545
	BEST VAL LOSS:    -3.174147
	BEST VAL EPOCH:   30
EPOCH 33 10.929371356964111
BEST VAL RESULT. SAVING MODEL...
EPOCH 33 EVAL: 
	CURRENT VAL LOSS: -3.177019
	BEST VAL LOSS:    -3.177019
	BEST VAL EPOCH:   33
EPOCH 34 10.944618463516235
EPOCH 34 EVAL: 
	CURRENT VAL LOSS: -3.135087
	BEST VAL LOSS:    -3.177019
	BEST VAL EPOCH:   33
EPOCH 35 10.838964700698853
EPOCH 35 EVAL: 
	CURRENT VAL LOSS: -3.111915
	BEST VAL LOSS:    -3.177019
	BEST VAL EPOCH:   33
EPOCH 36 10.816066026687622
EPOCH 36 EVAL: 
	CURRENT VAL LOSS: -3.138619
	BEST VAL LOSS:    -3.177019
	BEST VAL EPOCH:   33
EPOCH 37 10.810580253601074
BEST VAL RESULT. SAVING MODEL...
EPOCH 37 EVAL: 
	CURRENT VAL LOSS: -3.186508
	BEST VAL LOSS:    -3.186508
	BEST VAL EPOCH:   37
EPOCH 38 10.827070713043213
BEST VAL RESULT. SAVING MODEL...
EPOCH 38 EVAL: 
	CURRENT VAL LOSS: -3.189661
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 39 10.829816579818726
EPOCH 39 EVAL: 
	CURRENT VAL LOSS: -3.131736
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 40 10.813507080078125
EPOCH 40 EVAL: 
	CURRENT VAL LOSS: -3.181366
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 41 10.813847541809082
EPOCH 41 EVAL: 
	CURRENT VAL LOSS: -3.164144
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 42 10.817286014556885
EPOCH 42 EVAL: 
	CURRENT VAL LOSS: -3.157291
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 43 10.817542314529419
EPOCH 43 EVAL: 
	CURRENT VAL LOSS: -3.128713
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 44 10.812966346740723
EPOCH 44 EVAL: 
	CURRENT VAL LOSS: -3.167057
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 45 10.817285776138306
EPOCH 45 EVAL: 
	CURRENT VAL LOSS: -3.189143
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 46 10.803077697753906
EPOCH 46 EVAL: 
	CURRENT VAL LOSS: -3.168602
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 47 10.801594734191895
EPOCH 47 EVAL: 
	CURRENT VAL LOSS: -3.132560
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 48 10.788119554519653
EPOCH 48 EVAL: 
	CURRENT VAL LOSS: -3.184152
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 49 10.79150676727295
EPOCH 49 EVAL: 
	CURRENT VAL LOSS: -3.173085
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
EPOCH 50 10.804178476333618
EPOCH 50 EVAL: 
	CURRENT VAL LOSS: -3.130239
	BEST VAL LOSS:    -3.189661
	BEST VAL EPOCH:   38
