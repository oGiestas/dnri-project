Using factor graph MLP encoder.
ENCODER:  RefMLPEncoder(
  (mlp1): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=160, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp2): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=512, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp3): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp4): RefNRIMLP(
    (model): Sequential(
      (0): Linear(in_features=768, out_features=256, bias=True)
      (1): ELU(alpha=1.0, inplace=True)
      (2): Dropout(p=0.0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ELU(alpha=1.0, inplace=True)
    )
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc_out): Sequential(
    (0): Linear(in_features=256, out_features=256, bias=True)
    (1): ELU(alpha=1.0, inplace=True)
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ELU(alpha=1.0, inplace=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
)
Using learned recurrent interaction net decoder.
DECODER:  GraphRNNDecoder(
  (msg_fc1): ModuleList(
    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)
  )
  (msg_fc2): ModuleList(
    (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
  )
  (hidden_r): Linear(in_features=256, out_features=256, bias=False)
  (hidden_i): Linear(in_features=256, out_features=256, bias=False)
  (hidden_h): Linear(in_features=256, out_features=256, bias=False)
  (input_r): Linear(in_features=4, out_features=256, bias=True)
  (input_i): Linear(in_features=4, out_features=256, bias=True)
  (input_n): Linear(in_features=4, out_features=256, bias=True)
  (out_fc1): Linear(in_features=256, out_features=256, bias=True)
  (out_fc2): Linear(in_features=256, out_features=256, bias=True)
  (out_fc3): Linear(in_features=256, out_features=4, bias=True)
)
USING UNIFORM PRIOR
EPOCH 1 0
/mnt/aiongpfs/users/rgiesta/bsps6/dnri/dnri/models/decoders.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  hidden = torch.cuda.FloatTensor(inputs.size(0), inputs.size(2), self.msg_out_shape).fill_(0.)
BEST VAL RESULT. SAVING MODEL...
EPOCH 1 EVAL: 
	CURRENT VAL LOSS: 30.196367
	BEST VAL LOSS:    30.196367
	BEST VAL EPOCH:   1
EPOCH 2 12.207392692565918
BEST VAL RESULT. SAVING MODEL...
EPOCH 2 EVAL: 
	CURRENT VAL LOSS: -0.099589
	BEST VAL LOSS:    -0.099589
	BEST VAL EPOCH:   2
EPOCH 3 11.15323519706726
BEST VAL RESULT. SAVING MODEL...
EPOCH 3 EVAL: 
	CURRENT VAL LOSS: -0.221016
	BEST VAL LOSS:    -0.221016
	BEST VAL EPOCH:   3
EPOCH 4 11.153130054473877
BEST VAL RESULT. SAVING MODEL...
EPOCH 4 EVAL: 
	CURRENT VAL LOSS: -0.817797
	BEST VAL LOSS:    -0.817797
	BEST VAL EPOCH:   4
EPOCH 5 11.150264501571655
BEST VAL RESULT. SAVING MODEL...
EPOCH 5 EVAL: 
	CURRENT VAL LOSS: -1.224063
	BEST VAL LOSS:    -1.224063
	BEST VAL EPOCH:   5
EPOCH 6 11.150888204574585
BEST VAL RESULT. SAVING MODEL...
EPOCH 6 EVAL: 
	CURRENT VAL LOSS: -1.315341
	BEST VAL LOSS:    -1.315341
	BEST VAL EPOCH:   6
EPOCH 7 11.161314725875854
BEST VAL RESULT. SAVING MODEL...
EPOCH 7 EVAL: 
	CURRENT VAL LOSS: -1.707856
	BEST VAL LOSS:    -1.707856
	BEST VAL EPOCH:   7
EPOCH 8 11.157423496246338
BEST VAL RESULT. SAVING MODEL...
EPOCH 8 EVAL: 
	CURRENT VAL LOSS: -1.737992
	BEST VAL LOSS:    -1.737992
	BEST VAL EPOCH:   8
EPOCH 9 11.157784223556519
BEST VAL RESULT. SAVING MODEL...
EPOCH 9 EVAL: 
	CURRENT VAL LOSS: -1.833685
	BEST VAL LOSS:    -1.833685
	BEST VAL EPOCH:   9
EPOCH 10 11.163212537765503
BEST VAL RESULT. SAVING MODEL...
EPOCH 10 EVAL: 
	CURRENT VAL LOSS: -1.983813
	BEST VAL LOSS:    -1.983813
	BEST VAL EPOCH:   10
EPOCH 11 11.156764268875122
BEST VAL RESULT. SAVING MODEL...
EPOCH 11 EVAL: 
	CURRENT VAL LOSS: -2.148143
	BEST VAL LOSS:    -2.148143
	BEST VAL EPOCH:   11
EPOCH 12 11.151962757110596
BEST VAL RESULT. SAVING MODEL...
EPOCH 12 EVAL: 
	CURRENT VAL LOSS: -2.414428
	BEST VAL LOSS:    -2.414428
	BEST VAL EPOCH:   12
EPOCH 13 11.151835680007935
EPOCH 13 EVAL: 
	CURRENT VAL LOSS: -2.361699
	BEST VAL LOSS:    -2.414428
	BEST VAL EPOCH:   12
EPOCH 14 11.131467580795288
BEST VAL RESULT. SAVING MODEL...
EPOCH 14 EVAL: 
	CURRENT VAL LOSS: -2.589293
	BEST VAL LOSS:    -2.589293
	BEST VAL EPOCH:   14
EPOCH 15 11.129106998443604
EPOCH 15 EVAL: 
	CURRENT VAL LOSS: -2.483075
	BEST VAL LOSS:    -2.589293
	BEST VAL EPOCH:   14
EPOCH 16 11.130979776382446
BEST VAL RESULT. SAVING MODEL...
EPOCH 16 EVAL: 
	CURRENT VAL LOSS: -2.589864
	BEST VAL LOSS:    -2.589864
	BEST VAL EPOCH:   16
EPOCH 17 11.149192571640015
BEST VAL RESULT. SAVING MODEL...
EPOCH 17 EVAL: 
	CURRENT VAL LOSS: -2.599611
	BEST VAL LOSS:    -2.599611
	BEST VAL EPOCH:   17
EPOCH 18 11.151021480560303
BEST VAL RESULT. SAVING MODEL...
EPOCH 18 EVAL: 
	CURRENT VAL LOSS: -2.712238
	BEST VAL LOSS:    -2.712238
	BEST VAL EPOCH:   18
EPOCH 19 11.140673875808716
BEST VAL RESULT. SAVING MODEL...
EPOCH 19 EVAL: 
	CURRENT VAL LOSS: -2.809747
	BEST VAL LOSS:    -2.809747
	BEST VAL EPOCH:   19
EPOCH 20 11.134739398956299
BEST VAL RESULT. SAVING MODEL...
EPOCH 20 EVAL: 
	CURRENT VAL LOSS: -2.839276
	BEST VAL LOSS:    -2.839276
	BEST VAL EPOCH:   20
EPOCH 21 11.156825304031372
EPOCH 21 EVAL: 
	CURRENT VAL LOSS: -2.827432
	BEST VAL LOSS:    -2.839276
	BEST VAL EPOCH:   20
EPOCH 22 11.127611875534058
BEST VAL RESULT. SAVING MODEL...
EPOCH 22 EVAL: 
	CURRENT VAL LOSS: -2.879519
	BEST VAL LOSS:    -2.879519
	BEST VAL EPOCH:   22
EPOCH 23 11.140390157699585
EPOCH 23 EVAL: 
	CURRENT VAL LOSS: -2.875205
	BEST VAL LOSS:    -2.879519
	BEST VAL EPOCH:   22
EPOCH 24 11.134019136428833
BEST VAL RESULT. SAVING MODEL...
EPOCH 24 EVAL: 
	CURRENT VAL LOSS: -2.893339
	BEST VAL LOSS:    -2.893339
	BEST VAL EPOCH:   24
EPOCH 25 11.14711856842041
BEST VAL RESULT. SAVING MODEL...
EPOCH 25 EVAL: 
	CURRENT VAL LOSS: -2.995720
	BEST VAL LOSS:    -2.995720
	BEST VAL EPOCH:   25
EPOCH 26 11.144100189208984
EPOCH 26 EVAL: 
	CURRENT VAL LOSS: -2.989624
	BEST VAL LOSS:    -2.995720
	BEST VAL EPOCH:   25
EPOCH 27 11.12775206565857
EPOCH 27 EVAL: 
	CURRENT VAL LOSS: -2.941382
	BEST VAL LOSS:    -2.995720
	BEST VAL EPOCH:   25
EPOCH 28 11.132711410522461
EPOCH 28 EVAL: 
	CURRENT VAL LOSS: -2.872749
	BEST VAL LOSS:    -2.995720
	BEST VAL EPOCH:   25
EPOCH 29 11.128965616226196
BEST VAL RESULT. SAVING MODEL...
EPOCH 29 EVAL: 
	CURRENT VAL LOSS: -3.022726
	BEST VAL LOSS:    -3.022726
	BEST VAL EPOCH:   29
EPOCH 30 11.144977569580078
BEST VAL RESULT. SAVING MODEL...
EPOCH 30 EVAL: 
	CURRENT VAL LOSS: -3.083866
	BEST VAL LOSS:    -3.083866
	BEST VAL EPOCH:   30
EPOCH 31 11.144384145736694
BEST VAL RESULT. SAVING MODEL...
EPOCH 31 EVAL: 
	CURRENT VAL LOSS: -3.152179
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 32 11.150758743286133
EPOCH 32 EVAL: 
	CURRENT VAL LOSS: -3.051350
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 33 11.124234199523926
EPOCH 33 EVAL: 
	CURRENT VAL LOSS: -3.063564
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 34 11.132554292678833
EPOCH 34 EVAL: 
	CURRENT VAL LOSS: -3.145198
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 35 11.127543926239014
EPOCH 35 EVAL: 
	CURRENT VAL LOSS: -3.098758
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 36 11.132959365844727
EPOCH 36 EVAL: 
	CURRENT VAL LOSS: -3.069529
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 37 11.131867170333862
EPOCH 37 EVAL: 
	CURRENT VAL LOSS: -3.094447
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 38 11.127574920654297
EPOCH 38 EVAL: 
	CURRENT VAL LOSS: -3.053259
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 39 11.134980916976929
EPOCH 39 EVAL: 
	CURRENT VAL LOSS: -3.111431
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 40 11.13887619972229
EPOCH 40 EVAL: 
	CURRENT VAL LOSS: -3.071338
	BEST VAL LOSS:    -3.152179
	BEST VAL EPOCH:   31
EPOCH 41 11.133524894714355
BEST VAL RESULT. SAVING MODEL...
EPOCH 41 EVAL: 
	CURRENT VAL LOSS: -3.206131
	BEST VAL LOSS:    -3.206131
	BEST VAL EPOCH:   41
EPOCH 42 11.151504039764404
EPOCH 42 EVAL: 
	CURRENT VAL LOSS: -3.150799
	BEST VAL LOSS:    -3.206131
	BEST VAL EPOCH:   41
EPOCH 43 11.142180442810059
EPOCH 43 EVAL: 
	CURRENT VAL LOSS: -3.020304
	BEST VAL LOSS:    -3.206131
	BEST VAL EPOCH:   41
EPOCH 44 11.125877618789673
EPOCH 44 EVAL: 
	CURRENT VAL LOSS: -3.127894
	BEST VAL LOSS:    -3.206131
	BEST VAL EPOCH:   41
EPOCH 45 11.1342294216156
EPOCH 45 EVAL: 
	CURRENT VAL LOSS: -3.151528
	BEST VAL LOSS:    -3.206131
	BEST VAL EPOCH:   41
EPOCH 46 11.131575107574463
EPOCH 46 EVAL: 
	CURRENT VAL LOSS: -3.175980
	BEST VAL LOSS:    -3.206131
	BEST VAL EPOCH:   41
EPOCH 47 11.130637168884277
EPOCH 47 EVAL: 
	CURRENT VAL LOSS: -3.186850
	BEST VAL LOSS:    -3.206131
	BEST VAL EPOCH:   41
EPOCH 48 11.134178638458252
EPOCH 48 EVAL: 
	CURRENT VAL LOSS: -3.204509
	BEST VAL LOSS:    -3.206131
	BEST VAL EPOCH:   41
EPOCH 49 11.130425214767456
BEST VAL RESULT. SAVING MODEL...
EPOCH 49 EVAL: 
	CURRENT VAL LOSS: -3.233328
	BEST VAL LOSS:    -3.233328
	BEST VAL EPOCH:   49
EPOCH 50 11.147594928741455
EPOCH 50 EVAL: 
	CURRENT VAL LOSS: -3.175600
	BEST VAL LOSS:    -3.233328
	BEST VAL EPOCH:   49
